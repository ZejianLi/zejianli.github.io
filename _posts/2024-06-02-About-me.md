---
layout: post
title: About me
excerpt_image: /assets/images/zejianli_wide.png
categories: markdown
tags: [aboutme, top]
top: 1
---

![banner](/assets/images/zejianli_wide.png)


Lastly edited on 2025-05-03 18:57:50. 

## Biography 简介

Zejian Li is an Platform Top 100 Researcher with School of Software Technology, Zhejiang University, China. He is a member of International Design Institue, working closely with Prof. Lingyun Sun. He received his Ph.D. degree from Zhejiang University, China, in 2019. His Ph.D advisor is Prof. Yongchuan Tang. He was also supervised by Prof. Jonathan Lawry during his visit in Bristol University, UK. His research interests include generative models and intelligent design.

李泽健是浙江大学软件学院平台“百人计划”研究员，浙江大学国际设计研究院孙凌云教授团队成员。2019年在浙江大学获得计算机科学与技术博士学位，导师是汤永川教授。博士期间在英国布里斯托大学访问，导师是Jonathan Lawry。研究方向主要为生成模型和智能设计。


## Research Interests 研究兴趣

Generative Models, Intelligent Design
生成模型，智能设计

Specific research interests:
- Training and Distillation of Diffusion Models
- Controllable Image/3D generation
- Evaluation of Generative Content
- Interative Human-AI Cocreation

具体研究焦点：
- 扩散模型训练和蒸馏
- 可控 图像/3D 内容生成
- 生成内容质量评估
- 交互式人机协同创作


## Openings / Internship  招募和实习

I am looking for self-motivated PhD, master and undergraduate students to join my research group! I am also looking for postdoc and research assistant. Exchange or visiting students are also welcome. If you are interested in generative models, Human-AI cocreation and want to join us, please send me your CV to zejianlee at zju.edu.cn. For those who are pursuing master degrees, notice that right now I only have master quota of industrial design engineering, but not software engineering or artificial intelligence. However, the student's research direction is formed based on his or her capacity and interest.

团队招收博士生、硕士生和对科研感兴趣的本科生，以及博士后和科研助理，也欢迎不同学校的同学们过来访问交换。团队主要学术论文请看[publication部分](https://zejianli.github.io/markdown/2024/06/02/About-me.html#h-selected-publications-部分发表内容)。代表性作品包括[人工智能发展简史图谱](https://mp.weixin.qq.com/s/pwXEE0lUFsIGirGT_IXBsg)、[《运河·生长·万象》系列作品](https://mp.weixin.qq.com/s/_NjjqPFc5HAMMSyikLwF8g)、[“墨染”系列国画创作系统](http://www.idi.zju.edu.cn/project/2804.html)。代表性课程是[人工智能大模型前沿与应用](https://www.xueyinonline.com/detail/250928740)（通识课程）和[智能设计](https://mp.weixin.qq.com/s/KCXVSui02Q_W3fRVLDnInA)（研究生课程）。如果你对生成模型、人机协同创作的研究感兴趣，有意向加入我们团队，欢迎发邮件到zejianlee at zju.edu.cn，请附个人简历。因为我隶属设计学科，硕士名额大部分只有“工业设计工程”专业，（我也有人工智能、软件工程的导师资格，但名额大部分年份分不到）。如果联系读硕士研究生，请说明是否接受工业设计工程的名额。团队内往届工业设计工程专业的硕士生，技术背景的小同学从事生成算法研究，设计背景的小同学从事人机交互方向研究，组内相互合作搞点大招。我具有电子信息方向的博士导师资格，但每年名额不确定，团队已有博士生，会lead硕士生开展研究。


## Professional Activities 学术活动

Reviewer for ICLR, NeurIPS, CVPR, ICCV, ECCV, AAAI, ACM MM etc.

ICLR, NeurIPS, CVPR, ICCV, ECCV, AAAI, ACM MM 等AI顶会的审稿人。

## News 最新动态

* [2025-09-12] <br>
I give an online keynote talk on diffusion distillation and aligment invited by AITIME. The video is available of https://www.bilibili.com/video/BV15WpvzPEfZ/.
受AITIME邀请，我在线讲了一个有关“扩散模型蒸馏和偏好对齐”的报告，回放在https://www.bilibili.com/video/BV15WpvzPEfZ/。

* [2025-04-24 to 2025-05-01] <br>
I attend International Conference on Learning Representation in Singapore and CHI Conference on Human Factors in Computing Systems in Yokohama Tokyo. <br>
我在新加坡参加了ICLR 2025，之后参加了CHI 2025，都present 了paper。

* [2025-03-09] <br>
Our online course on Large Model is released on https://www.xueyinonline.com/detail/250928740. <br>
由孙凌云教授和我联合主讲的课程“人工智能大模型前沿与应用”已经在 https://www.xueyinonline.com/detail/250928740。后续会逐步更新增补新内容。

* [2024-05-29] <br>
I give a lecture for the course "The Introduction of AI Large Models for Everyone (Designers)" on the basic principles of AIGC algorithms. The playback can be found in the video posts of "Zheda Design". <br>
在浙江大学通识课“面向每个人（设计师）的AI大模型课”上讲授第五讲“AIGC基本原理”。回放可以在“浙大设计”微信视频号中观看。

* [2024-05-15] <br>
I give a lecture for the course "The Introduction of AI Large Models for Everyone (Designers)" on selected topics of data, algorithms and computation power. The playback can be found in the video posts of "Zheda Design". <br>
在浙江大学通识课“面向每个人（设计师）的AI大模型课”上讲授第三讲“数据、算法和算力”。回放可以在“浙大设计”微信视频号中观看。


## Selected Publications 部分发表内容

- Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models.<br>
**Zejian Li**, Yize Li, Chenye Meng, Zhongni Liu, Ling Yang, Shengyuan Zhang, Guang Yang, Changyuan Yang, Zhiyuan Yang, Lingyun Sun.<br> 
Accepted by ACM Multimedia 2025.

- ObjCtrl: Object-based Control Relaxation for Conditional Text-to-image Generation.<br>
Xinlong Zhang, **Zejian Li**, Wei Li, Xiaoyu Zhang, Jia Wei, Chengyu Lin, Yongchuan Tang.<br>
Accepted by ACM Multimedia 2025.

- Automating 3D Building Layouts with Graph Neural Networks for Architectural Space Layout Modeling. <br>
Quan Zhou, Yize Li, **Zejian Li**, Immanuel Koh.<br>
CAAD Futures 2025. Best paper award.


- Diffusion Distillation With Direct Preference Optimization For Efficient 3D LiDAR Scene Completion. <br>
An Zhao, Shengyuan Zhang, Ling Yang, **Zejian Li**, Jiale Wu, Haoran Xu, AnYang Wei, Perry Pengyun GU, Lingyun Sun.<br>
Accepted by AAAI 2026. https://arxiv.org/abs/2504.11447

- Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion.<br>
Shengyuan Zhang, An Zhao, Ling Yang, **Zejian Li\***, Chenye Meng, Haoran Xu, Tianrun Chen, AnYang Wei, Perry Pengyun GU, Lingyun Sun.<br>
Accepted by ICCV 2025. https://arxiv.org/abs/2412.03515

- Img2CAD: Conditioned 3D CAD Model Generation from Single Image with Structured Visual Geometry. <br>
Tianrun Chen, Chunan Yu, Yuanqi Hu, Jing Li, Tao Xu, Runlong Cao, Lanyun Zhu, Ying Zang, Yong Zhang, **Zejian Li**, Linyun Sun. <br>
Accepted by IEEE Transactions on Industrial Informatics, https://arxiv.org/abs/2410.03417

- Let Human Sketches Help: Empowering Challenging Image Segmentation Task with Freehand Sketches.<br>
Ying Zang, Runlong Cao, Jianqi Zhang, Yidong Han, Ziyue Cao, Wenjun Hu, Didi Zhu, Lanyun Zhu, **Zejian Li**, Deyi Ji, Tianrun Chen.<br>
https://arxiv.org/abs/2501.19329


- Syllables to Scenes: Literary-Guided Free-Viewpoint 3D Scene Synthesis from Japanese Haiku<br>
Chunan Yu, Yidong Han, Chaotao Ding, Ying Zang, Lanyun Zhu, Xinhao Chen, **Zejian Li**, Renjun Xu, Tianrun Chen.<br>
https://arxiv.org/abs/2502.11586

- LAION-SG: An Enhanced Large-Scale Dataset for Training Complex Image-Text Models with Structural Annotations.<br>
**Zejian Li**, Chenye Meng, Yize Li, Ling Yang, Shengyuan Zhang, Jiarui Ma, Jiayi Li, Guang Yang, Changyuan Yang, Zhiyuan Yang, Jinxiong Chang, Lingyun Sun.<br>
https://arxiv.org/abs/2412.08580

- Ink-Restorer: Virtual Restoration of Ancient Chinese Paintings
Inheriting Traditional Restoration Processe.<br> 
Ying Zhang, **Zejian Li\***, Jiesi Zhang, Fang Hu, Kewen Zhu, Liu Qi, Huanghuang Deng, Xiaoyu Chen, Lingyun Sun.<br> 
*ACM Conference on Human Factors in Computing Systems*, 2025. CCF-A.

- FusionProtor: A Mixed-Prototype Tool for Component-level Physical-to-Virtual 3D Transition and Simulation.<br>
Hongbo Zhang, Pei Chen, Xuelong Xie, Zhaoqu Jiang, Yifei Wu, **Zejian Li**, Xiaoyu Chen, Lingyun Sun.<br>
*ACM Conference on Human Factors in Computing Systems*, 2025. CCF-A.<br>
https://dl.acm.org/doi/10.1145/3706598.3713686

- CharacterCritique: Supporting Children's Development of Critical Thinking through Multi-Agent Interaction in Story Reading.<br>
Zizhen Wang, Jiangyu Pan, Duola Jin, Jingao Zhang, Jiacheng Cao, Chao Zhang, **Zejian Li**, Preben Hansen, Yijun Zhao, Shouqian Sun, Xianyue Qiao.<br>
*ACM Conference on Human Factors in Computing Systems*, 2025. CCF-A.<br>
https://dl.acm.org/doi/abs/10.1145/3706598.3713602

- Image Generation Evaluation: A Comprehensive Survey of Human and Automatic Evaluation.<br>
Qi Liu, Shuanglin Yang, **ZeJian Li\***, Lefan Hou, Chenye Meng, Ying Zhang, Lingyun Sun.<br>
*Frontiers of Information Technology & Electronic Engineering*, 2025. CCF-C

- Distribution Backtracking Builds A Faster Convergence Trajectory for Diffusion Distillation.<br>
Shengyuan Zhang, Ling Yang, **Zejian Li\***, An Zhao, Chenye Meng, Changyuan Yang,
Guang Yang, Zhiyuan Yang, Lingyun Sun<br>
*International Conference of Representation Learning*, 2025. TH-CPL-A


- Deep3DSketch-im: rapid high-fidelity AI 3D model generation by single freehand sketches.<br>
Tianrun Chen, Runlong Cao, **Zejian Li**, Ying Zang, Lingyun Sun.<br>
*Frontiers of Information Technology & Electronic Engineering*, 2024. CCF-C

- Reality3dsketch: Rapid 3d modeling of objects from single freehand sketches.<br>
Tianrun Chen, Chaotao Ding, Lanyun Zhu, Ying Zang, Yiyi Liao, **Zejian Li**, Ling Sun.<br>
IEEE Transactions on Multimedia. 2024. CCF-B

- RealtimeGen: An Intervenable AI Image Generation System for Commercial Digital Art Asset Creators.<br>
**Zejian Li**, Ying Zhang, Shengzhe Zhou, Qi Liu, Jiesi Zhang, Haoran Xu, Shuyao Chen, Xiaoyu Chen*, Lingyun Sun.<br>
*International Journal of Human–Computer Interaction*, 2024. CCF-B [paper](https://www.tandfonline.com/doi/full/10.1080/10447318.2024.2382508)


- Rapid 3D Model Generation with Intuitive 3D Input.<br>
Tianrun Chen, Chaotao Ding, Shangzhan Zhang, Chunan Yu, Ying Zang\*, **Zejian Li\***, Sida Peng, Lingyun Sun.<br>
*IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024. CCF-A [paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Rapid_3D_Model_Generation_with_Intuitive_3D_Input_CVPR_2024_paper.pdf)

- Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models.<br>
Shengzhe Zhou, **Zejian Li\***, Shengyuan Zhang, Lefan Hou, Changyuan Yang, Guang Yang, Zhiyuan Yang, Lingyun Sun.<br>
*AAAI Conference on Artificial Intelligence*, 2024. CCF-A 
[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28602/29171)

- SAM Fails to Segment Anything? - SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More.<br>
Tianrun Chen, Lanyun Zhu, Chao Ding, Runlong Cao, Shangzhan Zhang, Yan Wang, **Zejian Li**, Lingyun Sun, Papa Mao, Ying-Dong Zang<br>
*IEEE International Conference on Computer Vision Workshop*, 2023. 
[project](https://tianrun-chen.github.io/SAM-Adaptor/) [paper](https://arxiv.org/abs/2304.09148)


- Learning Object Consistency and Interaction in Image Generation from Scene Graphs.<br>
Yangkang Zhang, Chenye Meng, **Zejian Li\***, Pei Chen, Guang Yang, Changyuan Yang, Lingyun Sun. <br>
*International Joint Conference on Artificial Intelligence (IJCAI)*, 2023. CCF-A
[paper](https://www.ijcai.org/proceedings/2023/192)

- UI Layers Merger: Merging UI Layers via Visual Learning and Boundary Prior.<br>
Yun-nong Chen, Yan-kun Zhen, Chu-ning Shi, Jia-zhi Li, Liu-qing Chen, **Ze-jian Li**, Ling-yun Sun, Ting-ting Zhou, Yan-fang Chang. <br>
*Frontiers of Information Technology & Electronic Engineering (FITEE)*, 2022. CCF-C

- Magical Brush: A Symbol-Based Modern Chinese Painting System for Novices.<br>
Haoran Xu, Shuyao Chen, Ying Zhang.<br>
*ACM CHI Conference on Human Factors in Computing Systems*, 2023. CCF-A

- USIS: A unified semantic image synthesis model trained on a single or multiple samples.<br>
Pei Chen, **Zejian Li\***, Yangkang Zhang, Yongchuan Tang, Lingyun Sun. <br>
*Neurocomputing*, 2022. CCF-C

- Preserving Structural Consistency in Arbitrary Artist and Artwork Style Transfer.<br>
Jingyu Wu, Lefan Hou, **Zejian Li\***, Jun Liao, Li Liu, Lingyun Sun.<br>
*AAAI Conference on Artificial Intelligence*, 2023. CCF-A

- Recognizing Cognitive Load by a Hybrid Spatio-Temporal Causal Model from Multivariate Physiological Data.<br>
Zirui Yong, Li Liu, Guoxin Su, Xiaohu Li, Lingyun Sun, **Zejian Li**. <br>
*European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases* ,2022, CCF-B

- Few-Shot Incremental Learning for Label-to-Image Translation. <br>
Pei Chen, Yangkang Zhang, **Zejian Li\***, Lingyun Sun. <br>
*IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2022.  CCF-A

- Image Synthesis from Layout with Locality-Aware Mask Adaption. <br>
**Zejian Li**, Jingyu Wu, Immanuel Koh, Yongchuan Tang and Lingyun Sun*. <br>
*IEEE International Conference on Computer Vision*, 2021.  CCF-A

- FET-GAN: Font and Effect Transfer via K-shot Adaptive Instance Normalization. <br>
Wei Li, Yongxing He, Yanwei Qi, **Zejian Li** and Yongchuan Tang*. <br>
*AAAI Conference on Artificial Intelligence*, 2020. CCF-A

- A review of design intelligence: progress, problems, and challenges.<br>
Yongchuan Tang\*, Jiangjie Huang, Mengting Yao, Jia Wei, Wei Li, Yongxing He, **Zejian Li**. <br>
*Frontiers of Information Technology & Electronic Engineering*, 2020. CCF-C

- Learning Disentangled Representation with Pairwise Independence. <br>
**Zejian Li**, Yongchuan Tang\*, Wei Li and Yongxing He. <br>
*AAAI Conference on Artificial Intelligence*, 2019. CCF-A

- Unsupervised Disentangled Representation Learning with Analogical Relations.  <br>
**Zejian Li**, Yongchuan Tang\*, and Yongxing He. <br>
*International Joint Conference on Artificial Intelligence*, 2018. CCF-A



拉到最下的你，不管是拖下来还是翻下来的，都非常感谢你看到这里。如果还想更多了解我们团队的情（ba）况（gua），可以关注我和小同学们[的](https://www.xiaohongshu.com/user/profile/5de117030000000001000d84)[小](https://www.xiaohongshu.com/user/profile/5cffadd3000000001202e7b5)[红](https://www.xiaohongshu.com/user/profile/611fb7f6000000000101e933)[书](https://www.xiaohongshu.com/user/profile/5f92e666000000000100aca2)。

<!-- 

## 
Paragraphs are separated by a blank line.

2nd paragraph. *Italic*, **bold**, and `monospace`. Itemized lists
look like:

  * this one
  * that one
  * the other one

Note that --- not considering the asterisk --- the actual text
content starts at 4-columns in.

> Block quotes are
> written like so.
>
> They can span multiple paragraphs,
> if you like.

Use 3 dashes for an em-dash. Use 2 dashes for ranges (ex., "it's all
in chapters 12--14"). Three dots ... will be converted to an ellipsis.
Unicode is supported. ☺



An h2 header
------------

Here's a numbered list:

 1. first item
 2. second item
 3. third item

Note again how the actual text starts at 4 columns in (4 characters
from the left side). Here's a code sample:

    # Let me re-iterate ...
    for i in 1 .. 10 { do-something(i) }

As you probably guessed, indented 4 spaces. By the way, instead of
indenting the block, you can use delimited blocks, if you like:

~~~
define foobar() {
    print "Welcome to flavor country!";
}
~~~

(which makes copying & pasting easier). You can optionally mark the
delimited block for Pandoc to syntax highlight it:

~~~python
import time
# Quick, count to ten!
for i in range(10):
    # (but not *too* quick)
    time.sleep(0.5)
    print(i)
~~~



### An h3 header ###

Now a nested list:

 1. First, get these ingredients:

      * carrots
      * celery
      * lentils

 2. Boil some water.

 3. Dump everything in the pot and follow
    this algorithm:

        find wooden spoon
        uncover pot
        stir
        cover pot
        balance wooden spoon precariously on pot handle
        wait 10 minutes
        goto first step (or shut off burner when done)

    Do not bump wooden spoon or it will fall.

Notice again how text always lines up on 4-space indents (including
that last line which continues item 3 above).

Here's a link to [a website](http://foo.bar), to a [local
doc](local-doc.html), and to a [section heading in the current
doc](#an-h2-header). Here's a footnote [^1].

[^1]: Some footnote text.

Tables can look like this:

Name           Size  Material      Color
------------- -----  ------------  ------------
All Business      9  leather       brown
Roundabout       10  hemp canvas   natural
Cinderella       11  glass         transparent

Table: Shoes sizes, materials, and colors.

(The above is the caption for the table.) Pandoc also supports
multi-line tables:

--------  -----------------------
Keyword   Text
--------  -----------------------
red       Sunsets, apples, and
          other red or reddish
          things.

green     Leaves, grass, frogs
          and other things it's
          not easy being.
--------  -----------------------

A horizontal rule follows.

***

Here's a definition list:

apples
  : Good for making applesauce.

oranges
  : Citrus!

tomatoes
  : There's no "e" in tomatoe.

Again, text is indented 4 spaces. (Put a blank line between each
term and  its definition to spread things out more.)

Here's a "line block" (note how whitespace is honored):

| Line one
|   Line too
| Line tree

and images can be specified like so:

Inline math equation: $\omega = d\phi / dt$. Display
math should get its own line like so:

$$I = \int \rho R^{2} dV$$

And note that you can backslash-escape any punctuation characters
which you wish to be displayed literally, ex.: \`foo\`, \*bar\*, etc. -->
